{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow 2.2.2\n",
    "#others newest\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import tqdm.keras as tk\n",
    "# from keras_tqdm import TQDMNotebookCallback\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./new_train/new_train\"\n",
    "test_path = \"./new_val_in/new_val_in\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205942\n",
      "205942\n",
      "185300\n",
      "20500\n"
     ]
    }
   ],
   "source": [
    "data_list = glob(os.path.join(train_path, '*'))\n",
    "random.shuffle(data_list)\n",
    "print(int(len(data_list)*1))\n",
    "data_list = data_list[:len(data_list)]\n",
    "print(int(len(data_list)*1))\n",
    "\n",
    "train_list = data_list[:int(len(data_list)*0.9)-47]\n",
    "valid_list = data_list[int(len(data_list)*0.9)+95:]\n",
    "print(len(train_list))\n",
    "print(len(valid_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 10\n",
    "latent_dim = 256\n",
    "num_encoder_tokens = 2\n",
    "num_decoder_tokens = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator_x(train_list, batch_size):\n",
    "    index = 0\n",
    "    # shape of return data (batch_size, 19, [position + velocity])\n",
    "    # shape of return data (batch_size, 30, [position + velocity])\n",
    "    while True:\n",
    "        encoder_input_data = np.zeros((batch_size, 19, 2), dtype='float32')\n",
    "        decoder_input_data = np.zeros((batch_size, 30, 2), dtype='float32')\n",
    "        decoder_target_data = np.zeros((batch_size, 30, 2), dtype='float32')\n",
    "        for i in range(batch_size):\n",
    "            train_path = train_list[index]\n",
    "            with open(train_path, 'rb') as f:\n",
    "                data = pickle.load(f)                \n",
    "                agent_id = data['agent_id']\n",
    "                idx = np.where(data[\"track_id\"] == data[\"agent_id\"])[0][0]\n",
    "                \n",
    "                v_in_x = data[\"v_in\"][idx,:,0]\n",
    "                p_in_x = data[\"p_in\"][idx,:,0]\n",
    "                v_out_x = data[\"v_out\"][idx,:,0]\n",
    "                p_out_x = data[\"p_out\"][idx,:,0]\n",
    "                \n",
    "                encoder_input_data[i,:,0] = p_in_x\n",
    "                encoder_input_data[i,:,1] = v_in_x\n",
    "                \n",
    "                decoder_input_data[i,0,0] = p_in_x[-1]\n",
    "                decoder_input_data[i,0,1] = v_in_x[-1]\n",
    "                decoder_input_data[i,1:,0] = p_out_x[:-1]\n",
    "                decoder_input_data[i,1:,1] = v_out_x[:-1]\n",
    "                \n",
    "                decoder_target_data[i,:,0] = p_out_x\n",
    "                decoder_target_data[i,:,1] = v_out_x\n",
    "#                 print(data[\"p_out\"][idx])\n",
    "#                 print(data[\"v_in\"][idx])\n",
    "#                 print(\"p in x is \", p_in_x)\n",
    "#                 print(\"v in x is \", v_in_x)\n",
    "#                 print(\"p out x is \", p_out_x)\n",
    "#                 print(\"v out x is \", v_out_x)\n",
    "#                 print(\"decoder target data is \",decoder_target_data)\n",
    "                \n",
    "               \n",
    "            index += 1\n",
    "        if index == len(train_list):\n",
    "            index = 0\n",
    "\n",
    "        yield [encoder_input_data, decoder_input_data], decoder_target_data\n",
    "\n",
    "        \n",
    "def valid_generator_x(valid_list, batch_size):\n",
    "    index = 0\n",
    "    while True:\n",
    "        encoder_input_data = np.zeros((batch_size, 19, 2), dtype='float32')\n",
    "        decoder_input_data = np.zeros((batch_size, 30, 2), dtype='float32')\n",
    "        decoder_target_data = np.zeros((batch_size, 30, 2), dtype='float32')\n",
    "        for i in range(batch_size):\n",
    "            valid_path = valid_list[index]\n",
    "            with open(valid_path, 'rb') as f:\n",
    "                data = pickle.load(f)                \n",
    "                agent_id = data['agent_id']\n",
    "                idx = np.where(data[\"track_id\"] == data[\"agent_id\"])[0][0]\n",
    "                \n",
    "                v_in_x = data[\"v_in\"][idx,:,0]\n",
    "                p_in_x = data[\"p_in\"][idx,:,0]\n",
    "                v_out_x = data[\"v_out\"][idx,:,0]\n",
    "                p_out_x = data[\"p_out\"][idx,:,0]\n",
    "                \n",
    "                encoder_input_data[i,:,0] = p_in_x\n",
    "                encoder_input_data[i,:,1] = v_in_x\n",
    "                \n",
    "                decoder_input_data[i,0,0] = p_in_x[-1]\n",
    "                decoder_input_data[i,0,1] = v_in_x[-1]\n",
    "                decoder_input_data[i,1:,0] = p_out_x[:-1]\n",
    "                decoder_input_data[i,1:,1] = v_out_x[:-1]\n",
    "                \n",
    "                decoder_target_data[i,:,0] = p_out_x\n",
    "                decoder_target_data[i,:,1] = v_out_x\n",
    "                \n",
    "            index += 1\n",
    "        if index == len(valid_list):\n",
    "            index = 0\n",
    "\n",
    "        yield [encoder_input_data, decoder_input_data], decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/l6wu/.local/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#encoder portion\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True, activation=\"relu\")\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#decoder portion\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, activation=\"relu\")\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='linear')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_x = train_generator_x(train_list,100)\n",
    "valid_gen_x = valid_generator_x(valid_list,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss=root_mean_squared_error)\n",
    "checkpointer = ModelCheckpoint(filepath='./lstm_seqtoseq_x_weights.hdf5', verbose=2, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /home/l6wu/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 16.95516, saving model to ./lstm_seqtoseq_x_weights.hdf5\n",
      "1853/1853 - 613s - loss: 279.7547 - val_loss: 16.9552\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 16.95516 to 13.79492, saving model to ./lstm_seqtoseq_x_weights.hdf5\n",
      "1853/1853 - 626s - loss: 16.6014 - val_loss: 13.7949\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 13.79492 to 11.70671, saving model to ./lstm_seqtoseq_x_weights.hdf5\n",
      "1853/1853 - 472s - loss: 15.5486 - val_loss: 11.7067\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 11.70671\n",
      "1853/1853 - 525s - loss: 14.2477 - val_loss: 14.7750\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 11.70671\n",
      "1853/1853 - 566s - loss: 13.2341 - val_loss: 35.2933\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 11.70671\n",
      "1853/1853 - 394s - loss: 16.6094 - val_loss: 20.6853\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 11.70671\n",
      "1853/1853 - 408s - loss: 14.3033 - val_loss: 18.0212\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 11.70671 to 11.41871, saving model to ./lstm_seqtoseq_x_weights.hdf5\n",
      "1853/1853 - 425s - loss: 14.1849 - val_loss: 11.4187\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 11.41871\n",
      "1853/1853 - 421s - loss: 13.7697 - val_loss: 12.5123\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 11.41871\n",
      "1853/1853 - 368s - loss: 13.6014 - val_loss: 15.1900\n"
     ]
    }
   ],
   "source": [
    "hist_x = model.fit(train_gen_x,\n",
    "                        verbose=2,\n",
    "                        epochs=10,\n",
    "                        validation_data=valid_gen_x,\n",
    "                        steps_per_epoch=(len(train_list)/100),\n",
    "                        validation_steps=(len(valid_list)/100),\n",
    "                        callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drawing the training process...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "TrainERR=hist_x.history['loss']\n",
    "ValidERR=hist_x.history['val_loss']\n",
    "# print('@%f, Minimun error:%f, at iteration: %i' % (hist.history['val_loss'][epoch-1], np.min(np.asarray(ValidERR)),np.argmin(np.asarray(ValidERR))+1))\n",
    "print('drawing the training process...')\n",
    "plt.figure(2)\n",
    "plt.plot(range(1,10+1),TrainERR,'b',label='TrainERR')\n",
    "plt.plot(range(1,10+1),ValidERR,'r',label='ValidERR')\n",
    "plt.xlim([1,epochs])\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('error')\n",
    "plt.grid(True)\n",
    "fig1 = plt.gcf()\n",
    "fig1.savefig('lstm_p+v_x.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder model inference\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "#decoder model inference\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    #input seq is a scene \n",
    "    # Encode the input as state vectors.\n",
    "#     print(\"input seq shape is \",input_seq.shape)\n",
    "    input_shaped = np.empty((1,19,2))\n",
    "    input_shaped[0,:,:] = input_seq\n",
    "#     encoder_model.summary()\n",
    "#     input_shaped = np.reshape(input_seq, (input_seq.shape[0], 1, input_seq.shape[1]))\n",
    "#     print(\"inpiut shaped is \", input_shaped)\n",
    "    states_value = encoder_model.predict(input_shaped)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0,0,:] = input_seq[len(input_seq)-1] \n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    index = 0\n",
    "    decoded_sentence = ''\n",
    "    decoded_array = np.empty((30,2))\n",
    "    while index < 30:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        \n",
    "#         print(\"output tokens are \", output_tokens[0][0])\n",
    "        \n",
    "        # Sample a token\n",
    "        decoded_array[index,:] = output_tokens[0][0]\n",
    "\n",
    "        \n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, :] = output_tokens\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    \n",
    "        index += 1\n",
    "    \n",
    "    return decoded_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "columns.append(\"ID\")\n",
    "for i in range(30):\n",
    "    num = \"v\"+str(i+1)\n",
    "    columns.append(num)\n",
    "    \n",
    "df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3200/3200 [07:04<00:00,  7.54it/s]\n"
     ]
    }
   ],
   "source": [
    "#testing portion\n",
    "test_list = glob(os.path.join(test_path, '*'))\n",
    "print(len(test_list))\n",
    "\n",
    "for x in tqdm(test_list):\n",
    "    test_x = np.empty((30,2))\n",
    "    with open(x, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        new_row = []\n",
    "        scene_id = data['scene_idx']\n",
    "        new_row.append(scene_id)\n",
    "        agent_id = data['agent_id']\n",
    "        idx = np.where(data[\"track_id\"] == data[\"agent_id\"])[0][0]   \n",
    "        input_data = np.empty((19,2))\n",
    "        input_data[:,0] = data['p_in'][idx,:,0]\n",
    "        input_data[:,1] = data['v_in'][idx,:,0]\n",
    "        \n",
    "#         input_data = input_data[..., np.newaxis]\n",
    "        test_x = decode_sequence(input_data)\n",
    "        flat = test_x.flatten()\n",
    "        for i in range(30):\n",
    "            new_row.append(flat[i*2])\n",
    "#         for elem in flat:\n",
    "#             new_row.append(elem)\n",
    "        df_length = len(df)\n",
    "        df.loc[df_length] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ID'] = df['ID'].map(round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v21</th>\n",
       "      <th>v22</th>\n",
       "      <th>v23</th>\n",
       "      <th>v24</th>\n",
       "      <th>v25</th>\n",
       "      <th>v26</th>\n",
       "      <th>v27</th>\n",
       "      <th>v28</th>\n",
       "      <th>v29</th>\n",
       "      <th>v30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34189</td>\n",
       "      <td>592.591309</td>\n",
       "      <td>597.823792</td>\n",
       "      <td>596.257446</td>\n",
       "      <td>596.955688</td>\n",
       "      <td>598.331848</td>\n",
       "      <td>596.248901</td>\n",
       "      <td>594.985596</td>\n",
       "      <td>593.995789</td>\n",
       "      <td>595.057434</td>\n",
       "      <td>...</td>\n",
       "      <td>592.663574</td>\n",
       "      <td>592.575562</td>\n",
       "      <td>591.981812</td>\n",
       "      <td>591.548584</td>\n",
       "      <td>591.140747</td>\n",
       "      <td>590.765869</td>\n",
       "      <td>590.412598</td>\n",
       "      <td>590.068359</td>\n",
       "      <td>589.720154</td>\n",
       "      <td>589.354858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1454</td>\n",
       "      <td>577.975464</td>\n",
       "      <td>584.046875</td>\n",
       "      <td>582.518433</td>\n",
       "      <td>583.131470</td>\n",
       "      <td>584.040100</td>\n",
       "      <td>582.505554</td>\n",
       "      <td>579.632080</td>\n",
       "      <td>578.652710</td>\n",
       "      <td>579.677429</td>\n",
       "      <td>...</td>\n",
       "      <td>577.329956</td>\n",
       "      <td>577.211853</td>\n",
       "      <td>576.632935</td>\n",
       "      <td>576.206665</td>\n",
       "      <td>575.804871</td>\n",
       "      <td>575.434326</td>\n",
       "      <td>575.084106</td>\n",
       "      <td>574.741760</td>\n",
       "      <td>574.394592</td>\n",
       "      <td>574.029846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32404</td>\n",
       "      <td>592.432495</td>\n",
       "      <td>596.707764</td>\n",
       "      <td>595.079529</td>\n",
       "      <td>595.700439</td>\n",
       "      <td>597.666016</td>\n",
       "      <td>594.858704</td>\n",
       "      <td>595.484558</td>\n",
       "      <td>594.506165</td>\n",
       "      <td>595.580261</td>\n",
       "      <td>...</td>\n",
       "      <td>593.328491</td>\n",
       "      <td>593.270142</td>\n",
       "      <td>592.677368</td>\n",
       "      <td>592.248230</td>\n",
       "      <td>591.844299</td>\n",
       "      <td>591.473450</td>\n",
       "      <td>591.124695</td>\n",
       "      <td>590.784912</td>\n",
       "      <td>590.441772</td>\n",
       "      <td>590.081787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33991</td>\n",
       "      <td>410.373810</td>\n",
       "      <td>415.841522</td>\n",
       "      <td>414.202667</td>\n",
       "      <td>412.811432</td>\n",
       "      <td>415.685089</td>\n",
       "      <td>412.488312</td>\n",
       "      <td>396.534088</td>\n",
       "      <td>401.951233</td>\n",
       "      <td>405.982544</td>\n",
       "      <td>...</td>\n",
       "      <td>401.919464</td>\n",
       "      <td>401.425018</td>\n",
       "      <td>400.500336</td>\n",
       "      <td>399.780914</td>\n",
       "      <td>399.111176</td>\n",
       "      <td>398.468231</td>\n",
       "      <td>397.844482</td>\n",
       "      <td>397.229553</td>\n",
       "      <td>396.613373</td>\n",
       "      <td>395.985382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30427</td>\n",
       "      <td>589.056335</td>\n",
       "      <td>594.495972</td>\n",
       "      <td>592.954285</td>\n",
       "      <td>593.606995</td>\n",
       "      <td>594.904541</td>\n",
       "      <td>592.905029</td>\n",
       "      <td>591.064758</td>\n",
       "      <td>590.071777</td>\n",
       "      <td>591.124207</td>\n",
       "      <td>...</td>\n",
       "      <td>588.761230</td>\n",
       "      <td>588.671631</td>\n",
       "      <td>588.086670</td>\n",
       "      <td>587.660461</td>\n",
       "      <td>587.260132</td>\n",
       "      <td>586.892822</td>\n",
       "      <td>586.547607</td>\n",
       "      <td>586.211609</td>\n",
       "      <td>585.872375</td>\n",
       "      <td>585.516663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>7717</td>\n",
       "      <td>1876.974487</td>\n",
       "      <td>1894.121216</td>\n",
       "      <td>1891.891479</td>\n",
       "      <td>1892.166138</td>\n",
       "      <td>1891.750366</td>\n",
       "      <td>1891.659180</td>\n",
       "      <td>1876.698120</td>\n",
       "      <td>1873.236328</td>\n",
       "      <td>1876.527832</td>\n",
       "      <td>...</td>\n",
       "      <td>1868.197144</td>\n",
       "      <td>1868.032104</td>\n",
       "      <td>1866.277466</td>\n",
       "      <td>1865.046021</td>\n",
       "      <td>1863.924438</td>\n",
       "      <td>1862.934692</td>\n",
       "      <td>1862.043823</td>\n",
       "      <td>1861.213135</td>\n",
       "      <td>1860.403931</td>\n",
       "      <td>1859.576904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>5734</td>\n",
       "      <td>2051.281738</td>\n",
       "      <td>2051.780029</td>\n",
       "      <td>2049.785645</td>\n",
       "      <td>2051.290527</td>\n",
       "      <td>2050.904053</td>\n",
       "      <td>2050.419434</td>\n",
       "      <td>2058.102051</td>\n",
       "      <td>2054.647705</td>\n",
       "      <td>2058.257568</td>\n",
       "      <td>...</td>\n",
       "      <td>2048.538818</td>\n",
       "      <td>2048.069092</td>\n",
       "      <td>2045.934204</td>\n",
       "      <td>2044.352051</td>\n",
       "      <td>2042.865601</td>\n",
       "      <td>2041.498657</td>\n",
       "      <td>2040.211792</td>\n",
       "      <td>2038.960938</td>\n",
       "      <td>2037.701660</td>\n",
       "      <td>2036.387817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>33829</td>\n",
       "      <td>721.456787</td>\n",
       "      <td>727.287170</td>\n",
       "      <td>725.730225</td>\n",
       "      <td>726.341309</td>\n",
       "      <td>726.289185</td>\n",
       "      <td>725.940857</td>\n",
       "      <td>723.423462</td>\n",
       "      <td>722.188354</td>\n",
       "      <td>723.444214</td>\n",
       "      <td>...</td>\n",
       "      <td>720.251770</td>\n",
       "      <td>720.082031</td>\n",
       "      <td>719.347778</td>\n",
       "      <td>718.804504</td>\n",
       "      <td>718.293579</td>\n",
       "      <td>717.823242</td>\n",
       "      <td>717.379761</td>\n",
       "      <td>716.947571</td>\n",
       "      <td>716.510986</td>\n",
       "      <td>716.054016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>4515</td>\n",
       "      <td>579.292297</td>\n",
       "      <td>584.190369</td>\n",
       "      <td>582.616333</td>\n",
       "      <td>583.328552</td>\n",
       "      <td>585.048828</td>\n",
       "      <td>582.553101</td>\n",
       "      <td>581.900085</td>\n",
       "      <td>580.938416</td>\n",
       "      <td>581.984375</td>\n",
       "      <td>...</td>\n",
       "      <td>579.706116</td>\n",
       "      <td>579.642456</td>\n",
       "      <td>579.067383</td>\n",
       "      <td>578.650879</td>\n",
       "      <td>578.259766</td>\n",
       "      <td>577.901245</td>\n",
       "      <td>577.564453</td>\n",
       "      <td>577.237000</td>\n",
       "      <td>576.906494</td>\n",
       "      <td>576.560059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>17846</td>\n",
       "      <td>1936.662720</td>\n",
       "      <td>1925.233398</td>\n",
       "      <td>1923.653442</td>\n",
       "      <td>1924.955322</td>\n",
       "      <td>1924.221436</td>\n",
       "      <td>1924.397827</td>\n",
       "      <td>1939.125732</td>\n",
       "      <td>1935.587158</td>\n",
       "      <td>1938.966309</td>\n",
       "      <td>...</td>\n",
       "      <td>1929.274536</td>\n",
       "      <td>1929.192139</td>\n",
       "      <td>1927.283569</td>\n",
       "      <td>1925.937622</td>\n",
       "      <td>1924.704590</td>\n",
       "      <td>1923.610352</td>\n",
       "      <td>1922.619995</td>\n",
       "      <td>1921.692383</td>\n",
       "      <td>1920.787598</td>\n",
       "      <td>1919.864380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID           v1           v2           v3           v4           v5  \\\n",
       "0     34189   592.591309   597.823792   596.257446   596.955688   598.331848   \n",
       "1      1454   577.975464   584.046875   582.518433   583.131470   584.040100   \n",
       "2     32404   592.432495   596.707764   595.079529   595.700439   597.666016   \n",
       "3     33991   410.373810   415.841522   414.202667   412.811432   415.685089   \n",
       "4     30427   589.056335   594.495972   592.954285   593.606995   594.904541   \n",
       "...     ...          ...          ...          ...          ...          ...   \n",
       "3195   7717  1876.974487  1894.121216  1891.891479  1892.166138  1891.750366   \n",
       "3196   5734  2051.281738  2051.780029  2049.785645  2051.290527  2050.904053   \n",
       "3197  33829   721.456787   727.287170   725.730225   726.341309   726.289185   \n",
       "3198   4515   579.292297   584.190369   582.616333   583.328552   585.048828   \n",
       "3199  17846  1936.662720  1925.233398  1923.653442  1924.955322  1924.221436   \n",
       "\n",
       "               v6           v7           v8           v9  ...          v21  \\\n",
       "0      596.248901   594.985596   593.995789   595.057434  ...   592.663574   \n",
       "1      582.505554   579.632080   578.652710   579.677429  ...   577.329956   \n",
       "2      594.858704   595.484558   594.506165   595.580261  ...   593.328491   \n",
       "3      412.488312   396.534088   401.951233   405.982544  ...   401.919464   \n",
       "4      592.905029   591.064758   590.071777   591.124207  ...   588.761230   \n",
       "...           ...          ...          ...          ...  ...          ...   \n",
       "3195  1891.659180  1876.698120  1873.236328  1876.527832  ...  1868.197144   \n",
       "3196  2050.419434  2058.102051  2054.647705  2058.257568  ...  2048.538818   \n",
       "3197   725.940857   723.423462   722.188354   723.444214  ...   720.251770   \n",
       "3198   582.553101   581.900085   580.938416   581.984375  ...   579.706116   \n",
       "3199  1924.397827  1939.125732  1935.587158  1938.966309  ...  1929.274536   \n",
       "\n",
       "              v22          v23          v24          v25          v26  \\\n",
       "0      592.575562   591.981812   591.548584   591.140747   590.765869   \n",
       "1      577.211853   576.632935   576.206665   575.804871   575.434326   \n",
       "2      593.270142   592.677368   592.248230   591.844299   591.473450   \n",
       "3      401.425018   400.500336   399.780914   399.111176   398.468231   \n",
       "4      588.671631   588.086670   587.660461   587.260132   586.892822   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "3195  1868.032104  1866.277466  1865.046021  1863.924438  1862.934692   \n",
       "3196  2048.069092  2045.934204  2044.352051  2042.865601  2041.498657   \n",
       "3197   720.082031   719.347778   718.804504   718.293579   717.823242   \n",
       "3198   579.642456   579.067383   578.650879   578.259766   577.901245   \n",
       "3199  1929.192139  1927.283569  1925.937622  1924.704590  1923.610352   \n",
       "\n",
       "              v27          v28          v29          v30  \n",
       "0      590.412598   590.068359   589.720154   589.354858  \n",
       "1      575.084106   574.741760   574.394592   574.029846  \n",
       "2      591.124695   590.784912   590.441772   590.081787  \n",
       "3      397.844482   397.229553   396.613373   395.985382  \n",
       "4      586.547607   586.211609   585.872375   585.516663  \n",
       "...           ...          ...          ...          ...  \n",
       "3195  1862.043823  1861.213135  1860.403931  1859.576904  \n",
       "3196  2040.211792  2038.960938  2037.701660  2036.387817  \n",
       "3197   717.379761   716.947571   716.510986   716.054016  \n",
       "3198   577.564453   577.237000   576.906494   576.560059  \n",
       "3199  1922.619995  1921.692383  1920.787598  1919.864380  \n",
       "\n",
       "[3200 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_test = []\n",
    "columns_test.append(\"ID\")\n",
    "for i in range(38):\n",
    "    num = \"v\"+str(i+1)\n",
    "    columns_test.append(num)\n",
    "    \n",
    "df_test = pd.DataFrame(columns=columns_test)\n",
    "\n",
    "\n",
    "for x in test_list:\n",
    "    with open(x, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        new_row = []\n",
    "        scene_id = data['scene_idx']\n",
    "        new_row.append(scene_id)\n",
    "        agent_id = data['agent_id']\n",
    "        idx = np.where(data[\"track_id\"] == data[\"agent_id\"])[0][0]   \n",
    "        input_data = data['p_in'][idx,:,:]\n",
    "        for i in range(38):\n",
    "            new_row.append(input_data.flatten()[i])\n",
    "        df_length = len(df_test)\n",
    "        df_test.loc[df_length] = new_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v29</th>\n",
       "      <th>v30</th>\n",
       "      <th>v31</th>\n",
       "      <th>v32</th>\n",
       "      <th>v33</th>\n",
       "      <th>v34</th>\n",
       "      <th>v35</th>\n",
       "      <th>v36</th>\n",
       "      <th>v37</th>\n",
       "      <th>v38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34189.0</td>\n",
       "      <td>595.562073</td>\n",
       "      <td>936.528992</td>\n",
       "      <td>595.544006</td>\n",
       "      <td>935.963928</td>\n",
       "      <td>595.649536</td>\n",
       "      <td>936.135559</td>\n",
       "      <td>595.667480</td>\n",
       "      <td>935.907166</td>\n",
       "      <td>595.707275</td>\n",
       "      <td>...</td>\n",
       "      <td>596.247437</td>\n",
       "      <td>933.134216</td>\n",
       "      <td>596.408813</td>\n",
       "      <td>932.617249</td>\n",
       "      <td>596.376892</td>\n",
       "      <td>932.458801</td>\n",
       "      <td>596.398865</td>\n",
       "      <td>932.383728</td>\n",
       "      <td>596.435852</td>\n",
       "      <td>932.086731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1454.0</td>\n",
       "      <td>579.748535</td>\n",
       "      <td>1236.775146</td>\n",
       "      <td>579.938965</td>\n",
       "      <td>1236.378784</td>\n",
       "      <td>580.365906</td>\n",
       "      <td>1235.755371</td>\n",
       "      <td>580.250061</td>\n",
       "      <td>1235.585815</td>\n",
       "      <td>580.636536</td>\n",
       "      <td>...</td>\n",
       "      <td>582.202637</td>\n",
       "      <td>1229.476196</td>\n",
       "      <td>582.441162</td>\n",
       "      <td>1228.873901</td>\n",
       "      <td>582.233643</td>\n",
       "      <td>1228.338623</td>\n",
       "      <td>582.358765</td>\n",
       "      <td>1227.714478</td>\n",
       "      <td>582.552185</td>\n",
       "      <td>1227.146851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32404.0</td>\n",
       "      <td>596.773865</td>\n",
       "      <td>1526.008545</td>\n",
       "      <td>596.632812</td>\n",
       "      <td>1526.094360</td>\n",
       "      <td>596.576294</td>\n",
       "      <td>1526.078125</td>\n",
       "      <td>596.498291</td>\n",
       "      <td>1526.105225</td>\n",
       "      <td>596.269348</td>\n",
       "      <td>...</td>\n",
       "      <td>593.871521</td>\n",
       "      <td>1525.996704</td>\n",
       "      <td>593.444214</td>\n",
       "      <td>1525.877930</td>\n",
       "      <td>592.983887</td>\n",
       "      <td>1525.745117</td>\n",
       "      <td>592.521118</td>\n",
       "      <td>1525.561646</td>\n",
       "      <td>592.052429</td>\n",
       "      <td>1525.351685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33991.0</td>\n",
       "      <td>416.036377</td>\n",
       "      <td>1131.377930</td>\n",
       "      <td>415.903534</td>\n",
       "      <td>1131.828003</td>\n",
       "      <td>415.764526</td>\n",
       "      <td>1132.141724</td>\n",
       "      <td>415.624969</td>\n",
       "      <td>1132.613525</td>\n",
       "      <td>415.485992</td>\n",
       "      <td>...</td>\n",
       "      <td>413.496155</td>\n",
       "      <td>1136.546021</td>\n",
       "      <td>413.229736</td>\n",
       "      <td>1136.827271</td>\n",
       "      <td>412.953491</td>\n",
       "      <td>1137.106201</td>\n",
       "      <td>412.656830</td>\n",
       "      <td>1137.415649</td>\n",
       "      <td>412.440948</td>\n",
       "      <td>1137.703003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30427.0</td>\n",
       "      <td>591.568970</td>\n",
       "      <td>986.132019</td>\n",
       "      <td>591.628113</td>\n",
       "      <td>985.414978</td>\n",
       "      <td>591.787476</td>\n",
       "      <td>984.686584</td>\n",
       "      <td>591.843811</td>\n",
       "      <td>984.013428</td>\n",
       "      <td>591.922363</td>\n",
       "      <td>...</td>\n",
       "      <td>592.989380</td>\n",
       "      <td>975.482605</td>\n",
       "      <td>592.937866</td>\n",
       "      <td>974.617676</td>\n",
       "      <td>593.038269</td>\n",
       "      <td>973.842896</td>\n",
       "      <td>593.211975</td>\n",
       "      <td>973.422119</td>\n",
       "      <td>593.310730</td>\n",
       "      <td>972.728210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>7717.0</td>\n",
       "      <td>1875.832397</td>\n",
       "      <td>471.821625</td>\n",
       "      <td>1876.988770</td>\n",
       "      <td>472.846069</td>\n",
       "      <td>1878.359009</td>\n",
       "      <td>473.901123</td>\n",
       "      <td>1879.551514</td>\n",
       "      <td>474.995544</td>\n",
       "      <td>1880.836060</td>\n",
       "      <td>...</td>\n",
       "      <td>1893.428467</td>\n",
       "      <td>486.367584</td>\n",
       "      <td>1894.691895</td>\n",
       "      <td>487.410950</td>\n",
       "      <td>1895.904175</td>\n",
       "      <td>488.400177</td>\n",
       "      <td>1897.126709</td>\n",
       "      <td>489.408905</td>\n",
       "      <td>1898.337891</td>\n",
       "      <td>490.422180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>5734.0</td>\n",
       "      <td>2069.424072</td>\n",
       "      <td>635.513184</td>\n",
       "      <td>2068.171631</td>\n",
       "      <td>634.562622</td>\n",
       "      <td>2066.786621</td>\n",
       "      <td>633.569031</td>\n",
       "      <td>2065.407471</td>\n",
       "      <td>632.559387</td>\n",
       "      <td>2064.130371</td>\n",
       "      <td>...</td>\n",
       "      <td>2050.308594</td>\n",
       "      <td>621.376709</td>\n",
       "      <td>2048.978516</td>\n",
       "      <td>620.367310</td>\n",
       "      <td>2047.582764</td>\n",
       "      <td>619.339417</td>\n",
       "      <td>2046.292236</td>\n",
       "      <td>618.321838</td>\n",
       "      <td>2044.849243</td>\n",
       "      <td>617.266418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>33829.0</td>\n",
       "      <td>726.628113</td>\n",
       "      <td>909.115906</td>\n",
       "      <td>726.607422</td>\n",
       "      <td>909.657166</td>\n",
       "      <td>726.652161</td>\n",
       "      <td>909.966309</td>\n",
       "      <td>726.634827</td>\n",
       "      <td>909.686401</td>\n",
       "      <td>726.640259</td>\n",
       "      <td>...</td>\n",
       "      <td>727.459900</td>\n",
       "      <td>912.470154</td>\n",
       "      <td>727.510315</td>\n",
       "      <td>912.951233</td>\n",
       "      <td>727.566162</td>\n",
       "      <td>913.033325</td>\n",
       "      <td>727.508850</td>\n",
       "      <td>913.745483</td>\n",
       "      <td>727.478943</td>\n",
       "      <td>914.257568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>4515.0</td>\n",
       "      <td>582.553650</td>\n",
       "      <td>1419.214355</td>\n",
       "      <td>582.546326</td>\n",
       "      <td>1418.776367</td>\n",
       "      <td>582.498047</td>\n",
       "      <td>1418.246216</td>\n",
       "      <td>582.581909</td>\n",
       "      <td>1417.869873</td>\n",
       "      <td>582.607849</td>\n",
       "      <td>...</td>\n",
       "      <td>582.132080</td>\n",
       "      <td>1412.069458</td>\n",
       "      <td>582.254089</td>\n",
       "      <td>1410.913574</td>\n",
       "      <td>582.018677</td>\n",
       "      <td>1410.472656</td>\n",
       "      <td>582.125854</td>\n",
       "      <td>1409.070923</td>\n",
       "      <td>582.208496</td>\n",
       "      <td>1408.635132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>17846.0</td>\n",
       "      <td>1940.202637</td>\n",
       "      <td>536.739563</td>\n",
       "      <td>1939.490356</td>\n",
       "      <td>536.156799</td>\n",
       "      <td>1938.884644</td>\n",
       "      <td>535.588440</td>\n",
       "      <td>1938.568726</td>\n",
       "      <td>535.483887</td>\n",
       "      <td>1938.065552</td>\n",
       "      <td>...</td>\n",
       "      <td>1933.444336</td>\n",
       "      <td>531.046265</td>\n",
       "      <td>1933.015625</td>\n",
       "      <td>530.683533</td>\n",
       "      <td>1932.540283</td>\n",
       "      <td>530.343262</td>\n",
       "      <td>1932.202881</td>\n",
       "      <td>530.048889</td>\n",
       "      <td>1931.813599</td>\n",
       "      <td>529.707520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID           v1           v2           v3           v4  \\\n",
       "0     34189.0   595.562073   936.528992   595.544006   935.963928   \n",
       "1      1454.0   579.748535  1236.775146   579.938965  1236.378784   \n",
       "2     32404.0   596.773865  1526.008545   596.632812  1526.094360   \n",
       "3     33991.0   416.036377  1131.377930   415.903534  1131.828003   \n",
       "4     30427.0   591.568970   986.132019   591.628113   985.414978   \n",
       "...       ...          ...          ...          ...          ...   \n",
       "3195   7717.0  1875.832397   471.821625  1876.988770   472.846069   \n",
       "3196   5734.0  2069.424072   635.513184  2068.171631   634.562622   \n",
       "3197  33829.0   726.628113   909.115906   726.607422   909.657166   \n",
       "3198   4515.0   582.553650  1419.214355   582.546326  1418.776367   \n",
       "3199  17846.0  1940.202637   536.739563  1939.490356   536.156799   \n",
       "\n",
       "               v5           v6           v7           v8           v9  ...  \\\n",
       "0      595.649536   936.135559   595.667480   935.907166   595.707275  ...   \n",
       "1      580.365906  1235.755371   580.250061  1235.585815   580.636536  ...   \n",
       "2      596.576294  1526.078125   596.498291  1526.105225   596.269348  ...   \n",
       "3      415.764526  1132.141724   415.624969  1132.613525   415.485992  ...   \n",
       "4      591.787476   984.686584   591.843811   984.013428   591.922363  ...   \n",
       "...           ...          ...          ...          ...          ...  ...   \n",
       "3195  1878.359009   473.901123  1879.551514   474.995544  1880.836060  ...   \n",
       "3196  2066.786621   633.569031  2065.407471   632.559387  2064.130371  ...   \n",
       "3197   726.652161   909.966309   726.634827   909.686401   726.640259  ...   \n",
       "3198   582.498047  1418.246216   582.581909  1417.869873   582.607849  ...   \n",
       "3199  1938.884644   535.588440  1938.568726   535.483887  1938.065552  ...   \n",
       "\n",
       "              v29          v30          v31          v32          v33  \\\n",
       "0      596.247437   933.134216   596.408813   932.617249   596.376892   \n",
       "1      582.202637  1229.476196   582.441162  1228.873901   582.233643   \n",
       "2      593.871521  1525.996704   593.444214  1525.877930   592.983887   \n",
       "3      413.496155  1136.546021   413.229736  1136.827271   412.953491   \n",
       "4      592.989380   975.482605   592.937866   974.617676   593.038269   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "3195  1893.428467   486.367584  1894.691895   487.410950  1895.904175   \n",
       "3196  2050.308594   621.376709  2048.978516   620.367310  2047.582764   \n",
       "3197   727.459900   912.470154   727.510315   912.951233   727.566162   \n",
       "3198   582.132080  1412.069458   582.254089  1410.913574   582.018677   \n",
       "3199  1933.444336   531.046265  1933.015625   530.683533  1932.540283   \n",
       "\n",
       "              v34          v35          v36          v37          v38  \n",
       "0      932.458801   596.398865   932.383728   596.435852   932.086731  \n",
       "1     1228.338623   582.358765  1227.714478   582.552185  1227.146851  \n",
       "2     1525.745117   592.521118  1525.561646   592.052429  1525.351685  \n",
       "3     1137.106201   412.656830  1137.415649   412.440948  1137.703003  \n",
       "4      973.842896   593.211975   973.422119   593.310730   972.728210  \n",
       "...           ...          ...          ...          ...          ...  \n",
       "3195   488.400177  1897.126709   489.408905  1898.337891   490.422180  \n",
       "3196   619.339417  2046.292236   618.321838  2044.849243   617.266418  \n",
       "3197   913.033325   727.508850   913.745483   727.478943   914.257568  \n",
       "3198  1410.472656   582.125854  1409.070923   582.208496  1408.635132  \n",
       "3199   530.343262  1932.202881   530.048889  1931.813599   529.707520  \n",
       "\n",
       "[3200 rows x 39 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'./lstm_x.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
